\chapter{Conclusiones}\label{cap.conclusiones}

En este capítulo analizaremos si los objetivos \ref{sec:objetivos} planteados se han cumplido y se recapitulan las soluciones desarrolladas y los resultados obtenidos. Adicionalmente, sugeriremos las posibles líneas futuras de investigación por las que se puede extender este TFG. En líneas generales el objetivo global se ha alcanzado satisfactoriamente. Se ha conseguido por primera vez en el proyecto JdeRobot la navegación completamente autónoma en un entorno 3D utilizando un drone real, además de abrir la puerta al uso de miniordenadores embarcados a bordo de drones que tengan motores más potentes que los del Ar.Drone 2 de Parrot.

\section{Conclusiones}

Gran parte del trabajo aquí expuesto no ha formado parte de la programación directamente, sino que incluye el tiempo de investigación, aprendizaje de herramientas, tecnologías y habilidades que han tenido que ser adquiridas o adaptadas para programar con éxito la solución. Otra parte que se encuentra oculta detrás de los programas es el mérito de haber realizado los experimentos en un drone real cuyo comportamiento es inestable, en el que el ruido de los sensores condiciona el resultado de las pruebas y en el que la duración de las baterías reduce el número de pruebas diarias que se pueden realizar.

A continuación analizamos todos los subobjetivos para extraer las conclusiones que hemos obtenido en cada uno de ellos, recapitulando a la vez cómo han sido conseguidos:

\begin{enumerate}
	\item \textit{Integración del módulo de autolocalización 3D a partir de balizas visuales:} El funcionamiento ha sido validado mediante pruebas unitarias. Se ha reimplementado en Python el algoritmo que utilizaba \texttt{slam\_markers} y se ha integrado dentro del nodo \texttt{3DPathFollower}. Este módulo es capaz de estimar las coordenadas relativas con respecto a una baliza visual correctamente, permitiendo a la aplicación final realizar las correcciones necesarias en tiempo real y con la precisión necesaria.
	\item \textit{Desarrollo e integración de un módulo de navegación por balizas visuales:} Se ha desarrollado e integrado un PID capaz de ser aplicado para las diferentes balizas visuales utilizadas, aprovechando los recursos y mejorando el rendimiento de nuestra aplicación. Además, se ha ajustado el control del pilotaje tanto para escenarios simulados como para el drone real.
	\item \textit{Programación del comportamiento del drone en un autómata de estados finito:} Se han integrado la autolocalización, los controladores de aterrizaje, de despegue y de navegación siguiendo balizas visuales en un único autómata compacto, basado en 8 estados conectados a través de transiciones. Esto ha sido posible con la ayuda de \textsc{Visual States}.
	\item \textit{Validación experimental en el cuadricóptero  real:} Se han realizado pruebas tanto en el cuadricóptero simulado en Gazebo como principalmente con el cuadricóptero real Ar.Drone 2 de Parrot. Estas pruebas han sido tanto unitarias como globales, mostrando las capacidades de la navegación autónoma en 3D utilizando por primera vez balizas visuales. El comportamiento es ágil y preciso, además de eficiente ya que el algoritmo es capaz de ejecutar a una frecuencia de 33 Hz. 
	
	Los resultados obtenidos con miniordenador a bordo se han visto limitados debido a las restricciones de potencia del drone, que imposibilitan una prueba completamente a bordo. Aun así, se ha conseguido validar experimentalmente las capacidades de procesamiento del Intel Compute Stick \ref{sec:ics} de forma externa, dando como resultado un comportamiento ágil, suficientemente preciso, y con una frecuencia de ejecución de 20Hz, no muy diferente de la de un computador. De esta manera se deja abierta la puerta a posibles futuras aplicaciones con comportamientos autónomos totalmente a bordo. Se ha validado experimentalmente a través de la prueba global, en la que se ha ejecutado de principio a fin el algoritmo sin intervención externa de un humano, completando todos los estados y finalizando el ejercicio con el aterrizaje y detención del drone en la posición designada.
	
	
	%\item{\textbf{Diseño y desarrollo de una aplicación para la calibración de balizas bicolor arlequinadas:} Se ha conseguido desarrollar una aplicación que a través de una interfaz gráfica, modifique en tiempo real los filtros de color y que genere como resultado un fichero de configuración xml, el cual ha probado su utilidad ya que ha facilitado su futura utilización frente a cambios de luz o diferentes combinaciones de colores.}
	%\item{\textbf{Reimplementación y desarrollo de módulos de búsqueda:} Se ha conseguido desarrollar los dos módulos propuestos: uno dedicado para las balizas arlequinadas y otro para las balizas AprilTags. Ambos han sido validados experimentalmente y juntos han aumentado la autonomía a la hora de navegar del drone.}
	%\item{\textbf{Desarrollo de la inteligencia del dron materializándola en un autómata de estados finito:}	La aplicación 3DPathFollower es el resultado de este desarrollo e integración, junto con la ayuda de \textsc{Visual States}. Los estados han facilitado la realización de pruebas experimentales unitarias y globales. El algoritmo ha sido satisfactoriamente probado de principio a fin en un drone real y utilizando el co-procesador como unidad de procesamiento. Los estados creados dotarán de una base para futuras investigaciones y un ejemplo para generar otros algoritmos y aprovechar la modularidad que ofrece \textsc{Visual States}.}
	%\item{\textbf{Configuración del co-procesador a bordo del dron:} Este objetivo se ha visto modificado debido a las restricciones del dron, dado que no tenía suficiente potencia para ejecutar el comportamiento enviado por el co-procesador. Aun así, se ha conseguido configurar satisfactoriamente la infraestructura necesaria para externalizar el procesamiento en el Intel Compute Stick \ref{sec:ics}, además de aportar las herramientas y configuración necesarias para la ejecución y detención en remoto.}
	%\item{\textbf{Validación experimental en el cuadricóptero real:} Se han realizado satisfactoriamente tanto pruebas unitarias como globales, demostrando la efectividad de la prueba de concepto a la hora de utilizar una unidad como co-procesador y se ha mostrado la navegación autónoma en 3D utilizando por primera vez balizas de tipo AprilTags. La comparativa entre la ejecución tradicional y la nueva ha sido positiva, a pesar de que los resultados no son totalmente favorables para el co-procesador, el comportamiento y el rendimiento están muy cerca y no han supuesto un problema real para la ejecución de las pruebas. Esto abre la puerta a futuras nuevas aplicaciones utilizando esta infraestructura y cambiando posiblemente el dron por otro más potente u otro formato (como por ejemplo un avión).}
\end{enumerate}

Se ha aportado una nueva herramienta a la plataforma de JdeRobot, que ahora cuenta con un ejemplo de probado en un drone real navegación de forma autónoma, desde el despegue hasta el aterrizaje, realizando desplazamientos controlados. 

Todo el material audiovisual y avances que han ido teniendo lugar se pueden consultar en la Wiki oficial del proyecto: \url{http://jderobot.org/Andresjhe-tfg}

El código está subido al repositorio oficial del TFG y puede ser accedido sin restricciones para su revisión y mejora: \url{https://github.com/RoboticsURJC-students/2014-tfg-Andres-Hernandez/}

\section{Trabajos futuros}
Con este proyecto se han abierto algunas fronteras inexploradas lo que facilita el desarrollo de nuevas aplicaciones o la mejora de las ya existentes, en concreto en el ámbito de la navegación autónoma y la utilización de un miniordenador a bordo. A continuación se proponen algunas posibles líneas futuras a partir de los resultados y la experiencia obtenida durante la realización de este TFG:

\begin{itemize}
	\item Aumentar la complejidad de la navegación o probar en un escenario de exteriores. Ambas vías están directamente relacionadas con la mejora de los algoritmos desarrollados. 
	\item Sustitución de los algoritmos de visión por otros más sofisticados como técnicas de SLAM para autolocalización o el uso de \textit{DeepLearning}. Aumentaría la robustez y la cantidad de escenarios en los que puede ser utilizados, a pesar de que se sacrificaría eficiencia computacional y  en latencia.
	\item Sustitución del drone existente. La mayor dificultad a la hora de cumplir todos los objetivos ha estado directamente relacionada con las limitaciones del drone actual (derivas, falta de empuje vertical, ruido o defectos en sensores, etcétera). Un nuevo drone más potente puede ser la solución a los problemas encontrados.
\end{itemize}